{"cells":[{"cell_type":"markdown","metadata":{"id":"pa49bUnKyRgF"},"source":["# Multivariate time series prediction with LSTM\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7rZnJaGTWQw0","trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.callbacks import CSVLogger, EarlyStopping\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import pandas as pd\n","import seaborn as sns\n","import time\n","import gc\n","import sys\n","import pickle\n","\n","print(f\"Tensorflow Version: {tf.__version__}\")\n","print(f\"Pandas Version: {pd.__version__}\")\n","print(f\"Numpy Version: {np.__version__}\")\n","print(f\"System Version: {sys.version}\")\n","\n","matplotlib.rcParams['figure.figsize'] = (17, 5)\n","matplotlib.rcParams['axes.grid'] = False\n","sns.set_style(\"whitegrid\")\n"]},{"cell_type":"markdown","metadata":{"id":"TokBlnUhWFw9"},"source":["## Load Data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xyv_i85IWInT","trusted":true},"outputs":[],"source":["\n","df = pd.read_csv('data.csv', index_col=0)\n","print(\"DataFrame Shape: {} rows, {} columns\".format(*df.shape))\n","display(df.head())\n","print(f'Length of data : {len(df)}')\n","dataset = df.values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Data Loader Parameters\n","BATCH_SIZE = 128\n","BUFFER_SIZE = 1000\n","TRAIN_SPLIT = 18000\n","\n","# LSTM Parameters\n","EVALUATION_INTERVAL = 200\n","EPOCHS = 50\n","PATIENCE = 5\n","\n","# predictor index\n","PRED_INDEX=2 # 3rd column (RL) is what we want to predict\n","\n","\n","# Reproducibility\n","SEED = 13\n","tf.random.set_seed(SEED)"]},{"cell_type":"markdown","metadata":{"id":"qfbpcV0MWQzl"},"source":["This is an hourly series. \n","\n","Given a specific time, let's say you want to predict the RL to 6 hours into the future. In order to make this prediction, we choose to use 10 days of observations. Thus, we would create a window containing the last 240(10x24) observations to train the model. \n","\n","The function below returns the above described windows of time for the model to train on. The parameter `history_size` is the size of the past window of information. The `target_size` is how far in the future does the model need to learn to predict. The `target_size` is the label that needs to be predicted."]},{"cell_type":"markdown","metadata":{"id":"qoFJZmXBaxCc"},"source":[]},{"cell_type":"markdown","metadata":{"id":"qSfhTZi5r15R"},"source":["Let's have a look at how each of these features vary across time."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QdgC8zvGr21X","trusted":true},"outputs":[],"source":["df.plot(subplots=True, figsize=(25,5))"]},{"cell_type":"markdown","metadata":{"id":"cqStgZ-O1b3_"},"source":["We will standardize data "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dataset_=df.values\n","data_mean = dataset_[:TRAIN_SPLIT].mean(axis=0)\n","data_std = dataset_[:TRAIN_SPLIT].std(axis=0)\n","dataset = (dataset_-data_mean)/data_std\n","display(pd.DataFrame(dataset, columns = df.columns, index= df.index).head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d-rVX4d3OF86","trusted":true},"outputs":[],"source":["def multivariate_data(dataset, target, start_index, end_index, history_size,\n","                      target_size, step, single_step=False):\n","    data = []\n","    labels = []\n","\n","    start_index = start_index + history_size\n","    if end_index is None:\n","        end_index = len(dataset) - target_size\n","\n","    for i in range(start_index, end_index):\n","        indices = range(i-history_size, i, step)\n","        data.append(dataset[indices])\n","\n","        if single_step:\n","            labels.append(target[i+target_size])\n","        else:\n","            labels.append(target[i:i+target_size])\n","\n","    return np.array(data), np.array(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kZCk9fqyJZqX","trusted":true},"outputs":[],"source":["past_history = 240\n","future_target = 24\n","STEP = 1\n","\n","x_train_multi, y_train_multi = multivariate_data(dataset, dataset[:, PRED_INDEX], 0,\n","                                                 TRAIN_SPLIT, past_history,\n","                                                 future_target, STEP)\n","x_val_multi, y_val_multi = multivariate_data(dataset, dataset[:, PRED_INDEX],\n","                                             TRAIN_SPLIT, None, past_history,\n","                                             future_target, STEP)"]},{"cell_type":"markdown","metadata":{"id":"LImXPwAGRtWy"},"source":["Let's check out a sample data-point."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SpWDcBkQRwS-","trusted":true},"outputs":[],"source":["print (x_train_multi.shape,\n","       y_train_multi.shape,\n","       'Single window of past history : {}'.format(x_train_multi[0].shape),\n","       'Target river flow to predict : {}'.format(y_train_multi[0].shape),\n","       sep='\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cjR4PJArMOpA","trusted":true},"outputs":[],"source":["train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n","train_data_multi = train_data_multi.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n","\n","val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n","val_data_multi = val_data_multi.batch(BATCH_SIZE).repeat()"]},{"cell_type":"markdown","metadata":{"id":"IZcg8FWpSG8K"},"source":["Plotting a sample data-point."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ksXKVbwBV7D3","trusted":true},"outputs":[],"source":["def create_time_steps(length):\n","    return list(range(-length, 0))\n","\n","def plot_train_history(history, title):\n","    loss = history.history['loss']\n","    val_loss = history.history['val_loss']\n","\n","    epochs = range(len(loss))\n","\n","    plt.figure()\n","\n","    plt.plot(epochs, loss, 'b', label='Training loss')\n","    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n","    plt.title(title)\n","    # only plot values less than 1 \n","    ax = plt.gca()\n","    ax.set_ylim([-.1, 1.1])\n","    plt.legend()\n","\n","    plt.show()\n","\n","    \n","def multi_step_plot(history, true_future, prediction):\n","    plt.figure(figsize=(18, 6))\n","    num_in = create_time_steps(len(history))\n","    num_out = len(true_future)\n","\n","    plt.plot(num_in, np.array(history), label='History')\n","    plt.plot(np.arange(num_out)/STEP, np.array(true_future), '--bo',\n","           label='True Future')\n","    if prediction.any():\n","        plt.plot(np.arange(num_out)/STEP, np.array(prediction), '--ro',\n","                 label='Predicted Future')\n","    plt.legend(loc='upper left')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R6G8bacQR4w2","trusted":true},"outputs":[],"source":["for x, y in train_data_multi.take(2):\n","    print(x[0].shape, y[0].shape, )\n","    multi_step_plot(x[0][:, PRED_INDEX], y[0], np.array([0]))\n","    \n"]},{"cell_type":"markdown","metadata":{"id":"XOjz8DzZ4HFS"},"source":["Let us use two LSTM layers. Finally, since 24 predictions are made, the dense layer outputs 24 predictions."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_train_multi.shape[-2:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"byAl0NKSNBP6","trusted":true},"outputs":[],"source":["multi_step_model = tf.keras.models.Sequential()\n","multi_step_model.add(tf.keras.layers.LSTM(32,\n","                                          return_sequences=True,\n","                                          input_shape=x_train_multi.shape[-2:]))\n","multi_step_model.add(tf.keras.layers.LSTM(16, activation='relu'))\n","multi_step_model.add(tf.keras.layers.Dense(future_target))\n","\n","multi_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=1.0), loss='mae')\n","print(multi_step_model.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7uwOhXo3Oems","trusted":true},"outputs":[],"source":["early_stopping = EarlyStopping(monitor='val_loss', patience = PATIENCE, restore_best_weights=True)\n","multi_step_history = multi_step_model.fit(train_data_multi,\n","                                          epochs=EPOCHS,\n","                                          steps_per_epoch=EVALUATION_INTERVAL,\n","                                          validation_data=val_data_multi,\n","                                          validation_steps=EVALUATION_INTERVAL,\n","                                          callbacks=[early_stopping])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UKfQoBjQ5l7U","trusted":true},"outputs":[],"source":["plot_train_history(multi_step_history, 'Multi-Step Training and validation loss')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["multi_step_model.save(\"model.keras\")\n","# also save mean and standard diviation used in the model. \n","with open(\"model.param\",\"wb\") as fp:\n","    pickle.dump([data_mean, data_std], fp)\n","\n","\n","#multi_step_model=tf.keras.models.load_model('model_good.keras')\n","#with open(\"model_good.param\",\"rb\") as fp:\n","#    data_mean, data_std = pickle.load(fp)\n","#    print(f\"Mean : {data_mean} and std : {data_std}\")"]},{"cell_type":"markdown","metadata":{"id":"oDg94-yq4pas"},"source":["#### Predict a multi-step future\n","Let's now have a look at how well your network has learnt to predict the future."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dt22wq6fyIBU","trusted":true},"outputs":[],"source":["for x, y in val_data_multi.take(10):\n","    print(x.shape, np.array([x[0]]).shape)\n","    multi_step_plot(x[0][:,2], y[0], multi_step_model.predict(np.array([x[0]]))[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#del multi_step_model, val_data_multi, train_data_multi\n","#_ = gc.collect()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"time_series.ipynb","private_outputs":true,"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3.10.5 64-bit (system)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"},"vscode":{"interpreter":{"hash":"1721537060a5b8107cc7f26d404d8db36aed61f3a60e300859d12d171c7113cd"}}},"nbformat":4,"nbformat_minor":4}
