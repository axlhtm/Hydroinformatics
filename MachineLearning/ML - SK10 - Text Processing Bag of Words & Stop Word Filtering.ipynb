{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 10\n",
    "# Text Processing: Bag of Words & Stop Word Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bag of Words\n",
    "Bag of Words **menyederhanakan representasi teks sebagai sekumpulan kata serta mengabaikan grammar dan posisi tiap kata pada kalimat**. Text akan dikonversi menjadi lowercase dan tanda baca akan diabaikan. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Linux has been around since the mid-1190s.',\n",
       " 'Linux distributions include the Linux Kernel.',\n",
       " 'Linux is one of the most prominent open-source software.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "    'Linux has been around since the mid-1190s.', \n",
    "    'Linux distributions include the Linux Kernel.',\n",
    "    'Linux is one of the most prominent open-source software.'\n",
    "    ]\n",
    "\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Bag of Words dengan CountVectorizer\n",
    "Bag of Words model **dapat diterapkan dengan memanfaatkan CountVectorizer**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       "        [0, 0, 0, 1, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1]],\n",
       "       dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorized_x = vectorizer.fit_transform(corpus).todense()\n",
    "vectorizer_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1190s',\n",
       " 'around',\n",
       " 'been',\n",
       " 'distributions',\n",
       " 'has',\n",
       " 'include',\n",
       " 'is',\n",
       " 'kernel',\n",
       " 'linux',\n",
       " 'mid',\n",
       " 'most',\n",
       " 'of',\n",
       " 'one',\n",
       " 'open',\n",
       " 'prominent',\n",
       " 'since',\n",
       " 'software',\n",
       " 'source',\n",
       " 'the']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Euclidean Distance untuk Mengukur Jarak antar Dokumen (Vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jarak dokumen 1 dan 2: [[3.16227766]]\n",
      "Jarak dokumen 1 dan 3: [[3.74165739]]\n",
      "Jarak dokumen 2 dan 3: [[3.46410162]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "for i in range(len(vectorized_x)): \n",
    "    for j in range (i, len(vectorized_x)): \n",
    "        if i == j:\n",
    "            continue\n",
    "        jarak = euclidean_distances(vectorized_x[i], vectorized_x[j])\n",
    "        print(f'Jarak dokumen {i+1} dan {j+1}: {jarak}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Stop Word Filtering pada Text \n",
    "Stop Word Filtering **menyederhanakan representasi text dengan mengabaikan beberapa kata seperti determiners (the, a, an), auxiliary verbs (do, be, will) dan prepositions (on, in, at)**.\n",
    "\n",
    "#### - Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Linux has been around since the mid-1190s.',\n",
       " 'Linux distributions include the Linux Kernel.',\n",
       " 'Linux is one of the most prominent open-source software.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "    'Linux has been around since the mid-1190s.', \n",
    "    'Linux distributions include the Linux Kernel.',\n",
    "    'Linux is one of the most prominent open-source software.'\n",
    "    ]\n",
    "\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Stop Word Filtering dengan CountVectorizer \n",
    "Stop Word Filtering juga dapat **diterapkan dengan memanfaatkan CountVectorizer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 1, 1, 2, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "vectorized_x = vectorizer.fit_transform(corpus).todense()\n",
    "vectorized_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1190s',\n",
       " 'distributions',\n",
       " 'include',\n",
       " 'kernel',\n",
       " 'linux',\n",
       " 'mid',\n",
       " 'open',\n",
       " 'prominent',\n",
       " 'software',\n",
       " 'source']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38552727ee56418e1a63d6186a8a41f2f82ce7cc92f389e6de43124079e389b7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
